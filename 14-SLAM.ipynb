{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. What's SLAM?](#01)\n",
    "* [2. Concepts](#02)\n",
    "* [3. SLAM algorithms](#03)\n",
    "* [4. EKF SLAM](#04)\n",
    "  * [4.1 Formalizing the problem](#041)\n",
    "* [5. FastSLAM](#05)\n",
    "  * [5.1 Formalizing the problem](#051)"
   ],
   "metadata": {
    "toc": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What's SLAM? <a class=\"anchor\" id=\"01\"></a>\n",
    "*Simultaneous localization and mapping (SLAM)* is the computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. While this initially appears to be a chicken-and-egg problem there are several algorithms known for solving it, at least approximately, in tractable time for certain environments. Popular approximate solution methods include the particle filter, extended Kalman filter, Covariance intersection, and GraphSLAM. SLAM algorithms are based on concepts in computational geometry and computer vision, and are used in robot navigation, robotic mapping and odometry for virtual reality or augmented reality [SLAM:wiki](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concepts <a class=\"anchor\" id=\"02\"></a>\n",
    "\n",
    "Simultaneous Localization And Mapping (SLAM) is one of the most fundamental problems in robotics. It arises when our robot doesn't have access to a map of the environment nor the pose where it is located. In this way, the SLAM problem is more complex than the two separate ones in the previous chapters, localization and mapping.\n",
    "\n",
    "\n",
    "There are mainly two ways to address the SLAM problem:\n",
    "\n",
    "* Full SLAM: Estimates the whole path traversed at each step, that is: $$p( x_{1:k}, m_{1:L} | z_{1:k}, u_{1:k})$$\n",
    "* Online SLAM: Which only estimates the latest pose (we do not consider $x_{1:k-1}$), so: $$p(x_{k}, m_{1:L} | z_{1:k}, u_{1:k})$$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SLAM algorithms <a class=\"anchor\" id=\"03\"></a>\n",
    "\n",
    "* EKF SLAM\n",
    "* FastSLAM\n",
    "* GraphSLAM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EKF SLAM <a class=\"anchor\" id=\"04\"></a>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formalizing the problem <a class=\"anchor\" id=\"041\"></a>\n",
    "\n",
    "In the **online SLAM** problem, the state is defined by the robot pose as well as the position of the landmarks in the map, that is:\n",
    "\n",
    "$$s_k=[x_k | m_{x1} m_{y1} \\cdots m_{xL} m_{yL}]^T = [x_k | \\mathbf{m}]^T \\\\\\\\\\ dim(s_k)=3+2L $$ \n",
    "\n",
    "being:\n",
    "- $x_k$: the robot pose $[x,y,\\theta]$.\n",
    "- $\\mathbf{m}$: landmarks of the map $[m_x,m_y]$.\n",
    "- $L$: Number of landmarks.\n",
    "\n",
    "Since the robot doesn't know the total number of landmarks, $s_k$ augments in $[m_x, m_y]$ every time a new landmark is observed.\n",
    "\n",
    "The **EKF algorithm** was originally one of the most influential approaches to the online SLAM problem. We are going to employ it to fulfill the managers assignment, being its application here similar to the one we took to the problems of *localization* and *mapping*.\n",
    "\n",
    "As usual, for being able to use EKF we assume that $s_k$ follows a Gaussian distribution, that is $s_k \\sim N(\\mu_{s_k},\\Sigma_k)$, where: <br /><br />\n",
    "$$\\Sigma_k = \\begin{bmatrix}\n",
    "\\Sigma_{x_k} & \\Sigma_{xm_k} \\\\\n",
    "\\Sigma_{xm_k}^T & \\Sigma_{m_k} \\\\\n",
    "\\end{bmatrix}_{(3+2L) \\times (3+2L)}\n",
    "$$\n",
    "\n",
    "being:\n",
    "- $\\Sigma_{x_k}$: Covariance of the robot pose. Dimensions: $3x3$.\n",
    "- $\\Sigma_{xm_k}$: Correlation between pose and landmarks. Dimensions: $3x2L$. *Note: correlation means that error in $x_k$ affects error in $\\mathbf{m}$, that is, the pose is unknown and produces a correlation between it and the observed landmarks.* \n",
    "- $\\Sigma_{m_k}$: Covariance of the landmarks. Dimensions: $2Lx2L$.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Extended Kalman Filter SLAM example\n",
    "author: Atsushi Sakai (@Atsushi_twi)\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# EKF state covariance\n",
    "Cx = np.diag([0.5, 0.5, np.deg2rad(30.0)]) ** 2\n",
    "\n",
    "#  Simulation parameter\n",
    "Q_sim = np.diag([0.2, np.deg2rad(1.0)]) ** 2\n",
    "R_sim = np.diag([1.0, np.deg2rad(10.0)]) ** 2\n",
    "\n",
    "DT = 0.1  # time tick [s]\n",
    "SIM_TIME = 50.0  # simulation time [s]\n",
    "MAX_RANGE = 20.0  # maximum observation range\n",
    "M_DIST_TH = 2.0  # Threshold of Mahalanobis distance for data association.\n",
    "STATE_SIZE = 3  # State size [x,y,yaw]\n",
    "LM_SIZE = 2  # LM state size [x,y]\n",
    "\n",
    "show_animation = False\n",
    "\n",
    "\n",
    "def ekf_slam(xEst, PEst, u, z):\n",
    "    # Predict\n",
    "    S = STATE_SIZE\n",
    "    G, Fx = jacob_motion(xEst[0:S], u)\n",
    "    xEst[0:S] = motion_model(xEst[0:S], u)\n",
    "    PEst[0:S, 0:S] = G.T @ PEst[0:S, 0:S] @ G + Fx.T @ Cx @ Fx\n",
    "    initP = np.eye(2)\n",
    "\n",
    "    # Update\n",
    "    for iz in range(len(z[:, 0])):  # for each observation\n",
    "        min_id = search_correspond_landmark_id(xEst, PEst, z[iz, 0:2])\n",
    "\n",
    "        nLM = calc_n_lm(xEst)\n",
    "        if min_id == nLM:\n",
    "            # print(\"New LM\")\n",
    "            # Extend state and covariance matrix\n",
    "            xAug = np.vstack((xEst, calc_landmark_position(xEst, z[iz, :])))\n",
    "            PAug = np.vstack((np.hstack((PEst, np.zeros((len(xEst), LM_SIZE)))),\n",
    "                              np.hstack((np.zeros((LM_SIZE, len(xEst))), initP))))\n",
    "            xEst = xAug\n",
    "            PEst = PAug\n",
    "        lm = get_landmark_position_from_state(xEst, min_id)\n",
    "        y, S, H = calc_innovation(lm, xEst, PEst, z[iz, 0:2], min_id)\n",
    "\n",
    "        K = (PEst @ H.T) @ np.linalg.inv(S)\n",
    "        xEst = xEst + (K @ y)\n",
    "        PEst = (np.eye(len(xEst)) - (K @ H)) @ PEst\n",
    "\n",
    "    xEst[2] = pi_2_pi(xEst[2])\n",
    "\n",
    "    return xEst, PEst\n",
    "\n",
    "\n",
    "def calc_input():\n",
    "    v = 1.0  # [m/s]\n",
    "    yaw_rate = 0.1  # [rad/s]\n",
    "    u = np.array([[v, yaw_rate]]).T\n",
    "    return u\n",
    "\n",
    "\n",
    "def observation(xTrue, xd, u, RFID):\n",
    "    xTrue = motion_model(xTrue, u)\n",
    "\n",
    "    # add noise to gps x-y\n",
    "    z = np.zeros((0, 3))\n",
    "\n",
    "    for i in range(len(RFID[:, 0])):\n",
    "\n",
    "        dx = RFID[i, 0] - xTrue[0, 0]\n",
    "        dy = RFID[i, 1] - xTrue[1, 0]\n",
    "        d = math.hypot(dx, dy)\n",
    "        angle = pi_2_pi(math.atan2(dy, dx) - xTrue[2, 0])\n",
    "        if d <= MAX_RANGE:\n",
    "            dn = d + np.random.randn() * Q_sim[0, 0] ** 0.5  # add noise\n",
    "            angle_n = angle + np.random.randn() * Q_sim[1, 1] ** 0.5  # add noise\n",
    "            zi = np.array([dn, angle_n, i])\n",
    "            z = np.vstack((z, zi))\n",
    "\n",
    "    # add noise to input\n",
    "    ud = np.array([[\n",
    "        u[0, 0] + np.random.randn() * R_sim[0, 0] ** 0.5,\n",
    "        u[1, 0] + np.random.randn() * R_sim[1, 1] ** 0.5]]).T\n",
    "\n",
    "    xd = motion_model(xd, ud)\n",
    "    return xTrue, z, xd, ud\n",
    "\n",
    "\n",
    "def motion_model(x, u):\n",
    "    F = np.array([[1.0, 0, 0],\n",
    "                  [0, 1.0, 0],\n",
    "                  [0, 0, 1.0]])\n",
    "\n",
    "    B = np.array([[DT * math.cos(x[2, 0]), 0],\n",
    "                  [DT * math.sin(x[2, 0]), 0],\n",
    "                  [0.0, DT]])\n",
    "\n",
    "    x = (F @ x) + (B @ u)\n",
    "    return x\n",
    "\n",
    "\n",
    "def calc_n_lm(x):\n",
    "    n = int((len(x) - STATE_SIZE) / LM_SIZE)\n",
    "    return n\n",
    "\n",
    "\n",
    "def jacob_motion(x, u):\n",
    "    Fx = np.hstack((np.eye(STATE_SIZE), np.zeros(\n",
    "        (STATE_SIZE, LM_SIZE * calc_n_lm(x)))))\n",
    "\n",
    "    jF = np.array([[0.0, 0.0, -DT * u[0, 0] * math.sin(x[2, 0])],\n",
    "                   [0.0, 0.0, DT * u[0, 0] * math.cos(x[2, 0])],\n",
    "                   [0.0, 0.0, 0.0]], dtype=float)\n",
    "\n",
    "    G = np.eye(STATE_SIZE) + Fx.T @ jF @ Fx\n",
    "\n",
    "    return G, Fx,\n",
    "\n",
    "\n",
    "def calc_landmark_position(x, z):\n",
    "    zp = np.zeros((2, 1))\n",
    "\n",
    "    zp[0, 0] = x[0, 0] + z[0] * math.cos(x[2, 0] + z[1])\n",
    "    zp[1, 0] = x[1, 0] + z[0] * math.sin(x[2, 0] + z[1])\n",
    "\n",
    "    return zp\n",
    "\n",
    "\n",
    "def get_landmark_position_from_state(x, ind):\n",
    "    lm = x[STATE_SIZE + LM_SIZE * ind: STATE_SIZE + LM_SIZE * (ind + 1), :]\n",
    "\n",
    "    return lm\n",
    "\n",
    "\n",
    "def search_correspond_landmark_id(xAug, PAug, zi):\n",
    "    \"\"\"\n",
    "    Landmark association with Mahalanobis distance\n",
    "    \"\"\"\n",
    "\n",
    "    nLM = calc_n_lm(xAug)\n",
    "\n",
    "    min_dist = []\n",
    "\n",
    "    for i in range(nLM):\n",
    "        lm = get_landmark_position_from_state(xAug, i)\n",
    "        y, S, H = calc_innovation(lm, xAug, PAug, zi, i)\n",
    "        min_dist.append(y.T @ np.linalg.inv(S) @ y)\n",
    "\n",
    "    min_dist.append(M_DIST_TH)  # new landmark\n",
    "\n",
    "    min_id = min_dist.index(min(min_dist))\n",
    "\n",
    "    return min_id\n",
    "\n",
    "\n",
    "def calc_innovation(lm, xEst, PEst, z, LMid):\n",
    "    delta = lm - xEst[0:2]\n",
    "    q = (delta.T @ delta)[0, 0]\n",
    "    z_angle = math.atan2(delta[1, 0], delta[0, 0]) - xEst[2, 0]\n",
    "    zp = np.array([[math.sqrt(q), pi_2_pi(z_angle)]])\n",
    "    y = (z - zp).T\n",
    "    y[1] = pi_2_pi(y[1])\n",
    "    H = jacob_h(q, delta, xEst, LMid + 1)\n",
    "    S = H @ PEst @ H.T + Cx[0:2, 0:2]\n",
    "\n",
    "    return y, S, H\n",
    "\n",
    "\n",
    "def jacob_h(q, delta, x, i):\n",
    "    sq = math.sqrt(q)\n",
    "    G = np.array([[-sq * delta[0, 0], - sq * delta[1, 0], 0, sq * delta[0, 0], sq * delta[1, 0]],\n",
    "                  [delta[1, 0], - delta[0, 0], - q, - delta[1, 0], delta[0, 0]]])\n",
    "\n",
    "    G = G / q\n",
    "    nLM = calc_n_lm(x)\n",
    "    F1 = np.hstack((np.eye(3), np.zeros((3, 2 * nLM))))\n",
    "    F2 = np.hstack((np.zeros((2, 3)), np.zeros((2, 2 * (i - 1))),\n",
    "                    np.eye(2), np.zeros((2, 2 * nLM - 2 * i))))\n",
    "\n",
    "    F = np.vstack((F1, F2))\n",
    "\n",
    "    H = G @ F\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "def pi_2_pi(angle):\n",
    "    return (angle + math.pi) % (2 * math.pi) - math.pi\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    time = 0.0\n",
    "\n",
    "    # RFID positions [x, y]\n",
    "    RFID = np.array([[10.0, -2.0],\n",
    "                     [15.0, 10.0],\n",
    "                     [3.0, 15.0],\n",
    "                     [-5.0, 20.0]])\n",
    "\n",
    "    # State Vector [x y yaw v]'\n",
    "    xEst = np.zeros((STATE_SIZE, 1))\n",
    "    xTrue = np.zeros((STATE_SIZE, 1))\n",
    "    PEst = np.eye(STATE_SIZE)\n",
    "\n",
    "    xDR = np.zeros((STATE_SIZE, 1))  # Dead reckoning\n",
    "\n",
    "    # history\n",
    "    hxEst = xEst\n",
    "    hxTrue = xTrue\n",
    "    hxDR = xTrue\n",
    "\n",
    "    while SIM_TIME >= time:\n",
    "        time += DT\n",
    "        u = calc_input()\n",
    "\n",
    "        xTrue, z, xDR, ud = observation(xTrue, xDR, u, RFID)\n",
    "\n",
    "        xEst, PEst = ekf_slam(xEst, PEst, ud, z)\n",
    "\n",
    "        x_state = xEst[0:STATE_SIZE]\n",
    "\n",
    "        # store data history\n",
    "        hxEst = np.hstack((hxEst, x_state))\n",
    "        hxDR = np.hstack((hxDR, xDR))\n",
    "        hxTrue = np.hstack((hxTrue, xTrue))\n",
    "\n",
    "        if show_animation:  # pragma: no cover\n",
    "            plt.cla()\n",
    "            # for stopping simulation with the esc key.\n",
    "            plt.gcf().canvas.mpl_connect(\n",
    "                'key_release_event',\n",
    "                lambda event: [exit(0) if event.key == 'escape' else None])\n",
    "\n",
    "            plt.plot(RFID[:, 0], RFID[:, 1], \"*k\")\n",
    "            plt.plot(xEst[0], xEst[1], \".r\")\n",
    "\n",
    "            # plot landmark\n",
    "            for i in range(calc_n_lm(xEst)):\n",
    "                plt.plot(xEst[STATE_SIZE + i * 2],\n",
    "                         xEst[STATE_SIZE + i * 2 + 1], \"xg\")\n",
    "\n",
    "            plt.plot(hxTrue[0, :],\n",
    "                     hxTrue[1, :], \"-b\")\n",
    "            plt.plot(hxDR[0, :],\n",
    "                     hxDR[1, :], \"-k\")\n",
    "            plt.plot(hxEst[0, :],\n",
    "                     hxEst[1, :], \"-r\")\n",
    "            plt.axis(\"equal\")\n",
    "            plt.grid(True)\n",
    "            plt.pause(0.001)\n",
    "\n",
    "\n",
    "    plt.gcf().canvas.mpl_connect(\n",
    "        'key_release_event',\n",
    "        lambda event: [exit(0) if event.key == 'escape' else None])\n",
    "\n",
    "    plt.plot(RFID[:, 0], RFID[:, 1], \"*k\")\n",
    "    plt.plot(xEst[0], xEst[1], \".r\")\n",
    "\n",
    "    # plot landmark\n",
    "    for i in range(calc_n_lm(xEst)):\n",
    "        plt.plot(xEst[STATE_SIZE + i * 2],\n",
    "                    xEst[STATE_SIZE + i * 2 + 1], \"xg\")\n",
    "\n",
    "    plt.plot(hxTrue[0, :],\n",
    "                hxTrue[1, :], \"-b\")\n",
    "    plt.plot(hxDR[0, :],\n",
    "                hxDR[1, :], \"-k\")\n",
    "    plt.plot(hxEst[0, :],\n",
    "                hxEst[1, :], \"-r\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fast SLAM <a class=\"anchor\" id=\"05\"></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formalizing the problem <a class=\"anchor\" id=\"051\"></a>\n",
    "\n",
    "FastSLAM algorithm implementation is based on particle filters and belongs to the family of probabilistic SLAM approaches. It is used with feature-based maps (see gif above) or with occupancy grid maps.\n",
    "\n",
    "As it is shown, the particle filter differs from EKF by representing the robot's estimation through a set of particles. Each single particle has an independent belief, as it holds the pose $(x, y, \\theta)$ and an array of landmark locations $[(x_1, y_1), (x_2, y_2), ... (x_n, y_n)]$ for n landmarks.\n",
    "\n",
    "* The blue line is the true trajectory\n",
    "* The red line is the estimated trajectory\n",
    "* The red dots represent the distribution of particles\n",
    "* The black line represent dead reckoning tracjectory\n",
    "* The blue x is the observed and estimated landmarks\n",
    "* The black x is the true landmark\n",
    "\n",
    "I.e. Each particle maintains a deterministic pose and n-EKFs for each landmark and update it with each measurement.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "FastSLAM 1.0 example\n",
    "author: Atsushi Sakai (@Atsushi_twi)\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fast SLAM covariance\n",
    "Q = np.diag([3.0, np.deg2rad(10.0)]) ** 2\n",
    "R = np.diag([1.0, np.deg2rad(20.0)]) ** 2\n",
    "\n",
    "#  Simulation parameter\n",
    "Q_sim = np.diag([0.3, np.deg2rad(2.0)]) ** 2\n",
    "R_sim = np.diag([0.5, np.deg2rad(10.0)]) ** 2\n",
    "OFFSET_YAW_RATE_NOISE = 0.01\n",
    "\n",
    "DT = 0.1  # time tick [s]\n",
    "SIM_TIME = 50.0  # simulation time [s]\n",
    "MAX_RANGE = 20.0  # maximum observation range\n",
    "M_DIST_TH = 2.0  # Threshold of Mahalanobis distance for data association.\n",
    "STATE_SIZE = 3  # State size [x,y,yaw]\n",
    "LM_SIZE = 2  # LM state size [x,y]\n",
    "N_PARTICLE = 100  # number of particle\n",
    "NTH = N_PARTICLE / 1.5  # Number of particle for re-sampling\n",
    "\n",
    "show_animation = False\n",
    "\n",
    "\n",
    "class Particle:\n",
    "\n",
    "    def __init__(self, n_landmark):\n",
    "        self.w = 1.0 / N_PARTICLE\n",
    "        self.x = 0.0\n",
    "        self.y = 0.0\n",
    "        self.yaw = 0.0\n",
    "        # landmark x-y positions\n",
    "        self.lm = np.zeros((n_landmark, LM_SIZE))\n",
    "        # landmark position covariance\n",
    "        self.lmP = np.zeros((n_landmark * LM_SIZE, LM_SIZE))\n",
    "\n",
    "\n",
    "def fast_slam1(particles, u, z):\n",
    "    particles = predict_particles(particles, u)\n",
    "\n",
    "    particles = update_with_observation(particles, z)\n",
    "\n",
    "    particles = resampling(particles)\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def normalize_weight(particles):\n",
    "    sum_w = sum([p.w for p in particles])\n",
    "\n",
    "    try:\n",
    "        for i in range(N_PARTICLE):\n",
    "            particles[i].w /= sum_w\n",
    "    except ZeroDivisionError:\n",
    "        for i in range(N_PARTICLE):\n",
    "            particles[i].w = 1.0 / N_PARTICLE\n",
    "\n",
    "        return particles\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def calc_final_state(particles):\n",
    "    xEst = np.zeros((STATE_SIZE, 1))\n",
    "\n",
    "    particles = normalize_weight(particles)\n",
    "\n",
    "    for i in range(N_PARTICLE):\n",
    "        xEst[0, 0] += particles[i].w * particles[i].x\n",
    "        xEst[1, 0] += particles[i].w * particles[i].y\n",
    "        xEst[2, 0] += particles[i].w * particles[i].yaw\n",
    "\n",
    "    xEst[2, 0] = pi_2_pi(xEst[2, 0])\n",
    "    #  print(xEst)\n",
    "\n",
    "    return xEst\n",
    "\n",
    "\n",
    "def predict_particles(particles, u):\n",
    "    for i in range(N_PARTICLE):\n",
    "        px = np.zeros((STATE_SIZE, 1))\n",
    "        px[0, 0] = particles[i].x\n",
    "        px[1, 0] = particles[i].y\n",
    "        px[2, 0] = particles[i].yaw\n",
    "        ud = u + (np.random.randn(1, 2) @ R ** 0.5).T  # add noise\n",
    "        px = motion_model(px, ud)\n",
    "        particles[i].x = px[0, 0]\n",
    "        particles[i].y = px[1, 0]\n",
    "        particles[i].yaw = px[2, 0]\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def add_new_landmark(particle, z, Q_cov):\n",
    "    r = z[0]\n",
    "    b = z[1]\n",
    "    lm_id = int(z[2])\n",
    "\n",
    "    s = math.sin(pi_2_pi(particle.yaw + b))\n",
    "    c = math.cos(pi_2_pi(particle.yaw + b))\n",
    "\n",
    "    particle.lm[lm_id, 0] = particle.x + r * c\n",
    "    particle.lm[lm_id, 1] = particle.y + r * s\n",
    "\n",
    "    # covariance\n",
    "    dx = r * c\n",
    "    dy = r * s\n",
    "    d2 = dx**2 + dy**2\n",
    "    d = math.sqrt(d2)\n",
    "    Gz = np.array([[dx / d, dy / d],\n",
    "                   [-dy / d2, dx / d2]])\n",
    "    particle.lmP[2 * lm_id:2 * lm_id + 2] = np.linalg.inv(\n",
    "        Gz) @ Q_cov @ np.linalg.inv(Gz.T)\n",
    "\n",
    "    return particle\n",
    "\n",
    "\n",
    "def compute_jacobians(particle, xf, Pf, Q_cov):\n",
    "    dx = xf[0, 0] - particle.x\n",
    "    dy = xf[1, 0] - particle.y\n",
    "    d2 = dx ** 2 + dy ** 2\n",
    "    d = math.sqrt(d2)\n",
    "\n",
    "    zp = np.array(\n",
    "        [d, pi_2_pi(math.atan2(dy, dx) - particle.yaw)]).reshape(2, 1)\n",
    "\n",
    "    Hv = np.array([[-dx / d, -dy / d, 0.0],\n",
    "                   [dy / d2, -dx / d2, -1.0]])\n",
    "\n",
    "    Hf = np.array([[dx / d, dy / d],\n",
    "                   [-dy / d2, dx / d2]])\n",
    "\n",
    "    Sf = Hf @ Pf @ Hf.T + Q_cov\n",
    "\n",
    "    return zp, Hv, Hf, Sf\n",
    "\n",
    "\n",
    "def update_kf_with_cholesky(xf, Pf, v, Q_cov, Hf):\n",
    "    PHt = Pf @ Hf.T\n",
    "    S = Hf @ PHt + Q_cov\n",
    "\n",
    "    S = (S + S.T) * 0.5\n",
    "    s_chol = np.linalg.cholesky(S).T\n",
    "    s_chol_inv = np.linalg.inv(s_chol)\n",
    "    W1 = PHt @ s_chol_inv\n",
    "    W = W1 @ s_chol_inv.T\n",
    "\n",
    "    x = xf + W @ v\n",
    "    P = Pf - W1 @ W1.T\n",
    "\n",
    "    return x, P\n",
    "\n",
    "\n",
    "def update_landmark(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = np.array(particle.lm[lm_id, :]).reshape(2, 1)\n",
    "    Pf = np.array(particle.lmP[2 * lm_id:2 * lm_id + 2, :])\n",
    "\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q)\n",
    "\n",
    "    dz = z[0:2].reshape(2, 1) - zp\n",
    "    dz[1, 0] = pi_2_pi(dz[1, 0])\n",
    "\n",
    "    xf, Pf = update_kf_with_cholesky(xf, Pf, dz, Q_cov, Hf)\n",
    "\n",
    "    particle.lm[lm_id, :] = xf.T\n",
    "    particle.lmP[2 * lm_id:2 * lm_id + 2, :] = Pf\n",
    "\n",
    "    return particle\n",
    "\n",
    "\n",
    "def compute_weight(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = np.array(particle.lm[lm_id, :]).reshape(2, 1)\n",
    "    Pf = np.array(particle.lmP[2 * lm_id:2 * lm_id + 2])\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q_cov)\n",
    "\n",
    "    dx = z[0:2].reshape(2, 1) - zp\n",
    "    dx[1, 0] = pi_2_pi(dx[1, 0])\n",
    "\n",
    "    try:\n",
    "        invS = np.linalg.inv(Sf)\n",
    "    except np.linalg.linalg.LinAlgError:\n",
    "        print(\"singular\")\n",
    "        return 1.0\n",
    "\n",
    "    num = math.exp(-0.5 * dx.T @ invS @ dx)\n",
    "    den = 2.0 * math.pi * math.sqrt(np.linalg.det(Sf))\n",
    "\n",
    "    w = num / den\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def update_with_observation(particles, z):\n",
    "    for iz in range(len(z[0, :])):\n",
    "\n",
    "        landmark_id = int(z[2, iz])\n",
    "\n",
    "        for ip in range(N_PARTICLE):\n",
    "            # new landmark\n",
    "            if abs(particles[ip].lm[landmark_id, 0]) <= 0.01:\n",
    "                particles[ip] = add_new_landmark(particles[ip], z[:, iz], Q)\n",
    "            # known landmark\n",
    "            else:\n",
    "                w = compute_weight(particles[ip], z[:, iz], Q)\n",
    "                particles[ip].w *= w\n",
    "                particles[ip] = update_landmark(particles[ip], z[:, iz], Q)\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def resampling(particles):\n",
    "    \"\"\"\n",
    "    low variance re-sampling\n",
    "    \"\"\"\n",
    "\n",
    "    particles = normalize_weight(particles)\n",
    "\n",
    "    pw = []\n",
    "    for i in range(N_PARTICLE):\n",
    "        pw.append(particles[i].w)\n",
    "\n",
    "    pw = np.array(pw)\n",
    "\n",
    "    n_eff = 1.0 / (pw @ pw.T)  # Effective particle number\n",
    "    # print(n_eff)\n",
    "\n",
    "    if n_eff < NTH:  # resampling\n",
    "        w_cum = np.cumsum(pw)\n",
    "        base = np.cumsum(pw * 0.0 + 1 / N_PARTICLE) - 1 / N_PARTICLE\n",
    "        resample_id = base + np.random.rand(base.shape[0]) / N_PARTICLE\n",
    "\n",
    "        inds = []\n",
    "        ind = 0\n",
    "        for ip in range(N_PARTICLE):\n",
    "            while (ind < w_cum.shape[0] - 1) \\\n",
    "                    and (resample_id[ip] > w_cum[ind]):\n",
    "                ind += 1\n",
    "            inds.append(ind)\n",
    "\n",
    "        tmp_particles = particles[:]\n",
    "        for i in range(len(inds)):\n",
    "            particles[i].x = tmp_particles[inds[i]].x\n",
    "            particles[i].y = tmp_particles[inds[i]].y\n",
    "            particles[i].yaw = tmp_particles[inds[i]].yaw\n",
    "            particles[i].lm = tmp_particles[inds[i]].lm[:, :]\n",
    "            particles[i].lmP = tmp_particles[inds[i]].lmP[:, :]\n",
    "            particles[i].w = 1.0 / N_PARTICLE\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def calc_input(time):\n",
    "    if time <= 3.0:  # wait at first\n",
    "        v = 0.0\n",
    "        yaw_rate = 0.0\n",
    "    else:\n",
    "        v = 1.0  # [m/s]\n",
    "        yaw_rate = 0.1  # [rad/s]\n",
    "\n",
    "    u = np.array([v, yaw_rate]).reshape(2, 1)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def observation(xTrue, xd, u, rfid):\n",
    "    # calc true state\n",
    "    xTrue = motion_model(xTrue, u)\n",
    "\n",
    "    # add noise to range observation\n",
    "    z = np.zeros((3, 0))\n",
    "    for i in range(len(rfid[:, 0])):\n",
    "\n",
    "        dx = rfid[i, 0] - xTrue[0, 0]\n",
    "        dy = rfid[i, 1] - xTrue[1, 0]\n",
    "        d = math.hypot(dx, dy)\n",
    "        angle = pi_2_pi(math.atan2(dy, dx) - xTrue[2, 0])\n",
    "        if d <= MAX_RANGE:\n",
    "            dn = d + np.random.randn() * Q_sim[0, 0] ** 0.5  # add noise\n",
    "            angle_with_noize = angle + np.random.randn() * Q_sim[\n",
    "                1, 1] ** 0.5  # add noise\n",
    "            zi = np.array([dn, pi_2_pi(angle_with_noize), i]).reshape(3, 1)\n",
    "            z = np.hstack((z, zi))\n",
    "\n",
    "    # add noise to input\n",
    "    ud1 = u[0, 0] + np.random.randn() * R_sim[0, 0] ** 0.5\n",
    "    ud2 = u[1, 0] + np.random.randn() * R_sim[\n",
    "        1, 1] ** 0.5 + OFFSET_YAW_RATE_NOISE\n",
    "    ud = np.array([ud1, ud2]).reshape(2, 1)\n",
    "\n",
    "    xd = motion_model(xd, ud)\n",
    "\n",
    "    return xTrue, z, xd, ud\n",
    "\n",
    "\n",
    "def motion_model(x, u):\n",
    "    F = np.array([[1.0, 0, 0],\n",
    "                  [0, 1.0, 0],\n",
    "                  [0, 0, 1.0]])\n",
    "\n",
    "    B = np.array([[DT * math.cos(x[2, 0]), 0],\n",
    "                  [DT * math.sin(x[2, 0]), 0],\n",
    "                  [0.0, DT]])\n",
    "\n",
    "    x = F @ x + B @ u\n",
    "\n",
    "    x[2, 0] = pi_2_pi(x[2, 0])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def pi_2_pi(angle):\n",
    "    return (angle + math.pi) % (2 * math.pi) - math.pi\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    time = 0.0\n",
    "\n",
    "    # RFID positions [x, y]\n",
    "    RFID = np.array([[10.0, -2.0],\n",
    "                     [15.0, 10.0],\n",
    "                     [15.0, 15.0],\n",
    "                     [10.0, 20.0],\n",
    "                     [3.0, 15.0],\n",
    "                     [-5.0, 20.0],\n",
    "                     [-5.0, 5.0],\n",
    "                     [-10.0, 15.0]\n",
    "                     ])\n",
    "    n_landmark = RFID.shape[0]\n",
    "\n",
    "    # State Vector [x y yaw v]'\n",
    "    xEst = np.zeros((STATE_SIZE, 1))  # SLAM estimation\n",
    "    xTrue = np.zeros((STATE_SIZE, 1))  # True state\n",
    "    xDR = np.zeros((STATE_SIZE, 1))  # Dead reckoning\n",
    "\n",
    "    # history\n",
    "    hxEst = xEst\n",
    "    hxTrue = xTrue\n",
    "    hxDR = xTrue\n",
    "\n",
    "    particles = [Particle(n_landmark) for _ in range(N_PARTICLE)]\n",
    "\n",
    "    while SIM_TIME >= time:\n",
    "        time += DT\n",
    "        u = calc_input(time)\n",
    "\n",
    "        xTrue, z, xDR, ud = observation(xTrue, xDR, u, RFID)\n",
    "\n",
    "        particles = fast_slam1(particles, ud, z)\n",
    "\n",
    "        xEst = calc_final_state(particles)\n",
    "\n",
    "        x_state = xEst[0: STATE_SIZE]\n",
    "\n",
    "        # store data history\n",
    "        hxEst = np.hstack((hxEst, x_state))\n",
    "        hxDR = np.hstack((hxDR, xDR))\n",
    "        hxTrue = np.hstack((hxTrue, xTrue))\n",
    "\n",
    "        if show_animation:  # pragma: no cover\n",
    "            plt.cla()\n",
    "            # for stopping simulation with the esc key.\n",
    "            plt.gcf().canvas.mpl_connect(\n",
    "                'key_release_event', lambda event:\n",
    "                [exit(0) if event.key == 'escape' else None])\n",
    "            plt.plot(RFID[:, 0], RFID[:, 1], \"*k\")\n",
    "\n",
    "            for i in range(N_PARTICLE):\n",
    "                plt.plot(particles[i].x, particles[i].y, \".r\")\n",
    "                plt.plot(particles[i].lm[:, 0], particles[i].lm[:, 1], \"xb\")\n",
    "\n",
    "            plt.plot(hxTrue[0, :], hxTrue[1, :], \"-b\")\n",
    "            plt.plot(hxDR[0, :], hxDR[1, :], \"-k\")\n",
    "            plt.plot(hxEst[0, :], hxEst[1, :], \"-r\")\n",
    "            plt.plot(xEst[0], xEst[1], \"xk\")\n",
    "            plt.axis(\"equal\")\n",
    "            plt.grid(True)\n",
    "            plt.pause(0.001)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.cla()\n",
    "    # for stopping simulation with the esc key.\n",
    "    plt.gcf().canvas.mpl_connect(\n",
    "        'key_release_event', lambda event:\n",
    "        [exit(0) if event.key == 'escape' else None])\n",
    "    plt.plot(RFID[:, 0], RFID[:, 1], \"*k\")\n",
    "\n",
    "    for i in range(N_PARTICLE):\n",
    "        plt.plot(particles[i].x, particles[i].y, \".r\")\n",
    "        plt.plot(particles[i].lm[:, 0], particles[i].lm[:, 1], \"xb\")\n",
    "\n",
    "    plt.plot(hxTrue[0, :], hxTrue[1, :], \"-b\")\n",
    "    plt.plot(hxDR[0, :], hxDR[1, :], \"-k\")\n",
    "    plt.plot(hxEst[0, :], hxEst[1, :], \"-r\")\n",
    "    plt.plot(xEst[0], xEst[1], \"xk\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('env_3.7': venv)",
   "language": "python",
   "name": "python37164bitenv37venv0cd5c56ff19149c58d9706969bfe072f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Topics",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}